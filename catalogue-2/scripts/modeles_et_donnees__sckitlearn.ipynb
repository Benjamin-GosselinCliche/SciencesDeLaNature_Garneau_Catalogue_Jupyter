{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdaaef25",
   "metadata": {},
   "source": [
    "# Modèles et données\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56c59c3",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <div style=\"display: inline-block; position: relative; width: 350px;\">\n",
    "        <img src=\"../img/_4c492367-b76e-4fc2-b295-5a1cd0fad49b.jpeg\" alt=\"Dessin\" style=\"width: 100%;\"/>\n",
    "        <p style=\"text-align: center; margin-top: 5px;\">\n",
    "            <span style=\"font-style: italic; font-size: 16px;\"> Fit Global</span><br/>\n",
    "            <span style=\"font-style: italic; font-size: 12px;\">Image générée par DALL·E 3, mars 2024 </span>\n",
    "        </p>\n",
    "    </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085ecc8a",
   "metadata": {},
   "source": [
    "---\n",
    "## Mise en contexte\n",
    "\n",
    "### Principe fondamental \n",
    "\n",
    "Un principe fondamental de la science empirique consiste à apposer un modèle $M$ sur un ensemble de données $D$. Classiquement, l'ensemble de données $D$ consiste en un ensemble de données expérimentales, c'est-à-dire des valeurs mesurées, et le modèle $M$ est une fonction mathématique d'une ou plusieurs variables, comprenant un ou plusieurs paramètres. \n",
    "\n",
    "L'idée est de déterminer la valeur numérique de chaque paramètres du modèle $M$ qui fait en sorte que celui-ci correspond le mieux à l'ensemble de données $D$. Plus précisement, il s'agit d'appliquer une méthode d'optimisation qui minimise une certaine fonction de coût qui représente les différences entre les valeurs prédites par le modèle et les valeurs réelles des données (généralement appelées les résidus). Une méthode courante est la méthode des moindres carrés. Les paramètres optimaux seront ceux qui minimisent la somme des carrés des résidus.      \n",
    "\n",
    "Aussi, des méthodes statistiques complexes, impliquant la matrice de covariance, permettent de calculer une incertitude associée à ces paramètres. Il est également possible de calculer des mesures de performance tel que le coefficient de détermination $R^2$. Plus $R^2$ est proche de 1, meilleure est l'adéquation du modèle aux données.\n",
    "\n",
    "Ayant alors établit ce modèle $M$, celui-ci peut être utilisé pour effectuer des prédictions, tant pour les phénomènes naturels que pour le contrôle technologique. C'est exactement le même principe qui est appliqué dans les algorithmes d'apprentissage machine à la base de l'intelligence artificielle. \n",
    "\n",
    "###  Librairie scipy et la méthode curve_fit\n",
    "\n",
    "Pour n'importe quel ensemble de donnée de ce notebook, la méthode est la suivante:\n",
    "\n",
    "1. **Définition du modèle** :\n",
    "   Nous définissons une fonction appelée `modele`. Cette fonction prend $n$ variables ($x$, $y$, $t$, etc.) et $p$ paramètres ($a$, $b$, $alpha$, etc). \n",
    "\n",
    "2. **Générer des données factices** :\n",
    "   En principe l'ensemble de données $D$ est importé depuis un fichier. Dans ce notebook, l'ensemble des données est simulé. \n",
    "\n",
    "3. **Ajustement de courbe** :\n",
    "   Nous utilisons la fonction `curve_fit` de la bibliothèque Scipy pour ajuster notre modèle aux données. Cette fonction retourne deux valeurs : `popt`, qui contient les paramètres optimaux du modèle, et `pcov`, qui est la matrice de covariance contenant des informations sur les incertitudes sur ces paramètres.\n",
    "\n",
    "4. **Paramètres optimaux** :\n",
    "   Nous extrayons les paramètres optimaux `a_fit` et `b_fit` à partir de `popt`. Ces valeurs représentent les paramètres optimaux du modèle qui ont été trouvés par l'ajustement du modèle aux données.\n",
    "\n",
    "5. **Calcul des incertitudes sur les paramètres optimaux** :\n",
    "   Nous calculons les incertitudes sur les paramètres optimaux  à partir de la matrice de covariance `pcov`. Pour ce faire, nous extrayons les écarts types des paramètres de la diagonale de la matrice de covariance en utilisant la fonction `np.sqrt(np.diag(pcov))`.\n",
    "\n",
    "6. **Prédiction du modèle** :\n",
    "   Nous utilisons les paramètres ajustés `a_fit` et `b_fit` pour prédire les valeurs de `y` en utilisant notre modèle linéaire. Les valeurs prédites sont stockées dans `y_pred`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197e9bdb",
   "metadata": {},
   "source": [
    "---\n",
    "# Objectifs:\n",
    "- Comprendre la méthode générale\n",
    "- Utiliser la librairie scipy et la méthode curve_fit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3cdd50",
   "metadata": {},
   "source": [
    "---\n",
    "## Exemple 1: Modèle linéaire\n",
    "\n",
    "Un grand nombre de phénomène sont représentés par un modèle linéaire simple. Ce modèle est une droite de type $f(x) = ax + b$. La variable indépendante est $x$ et la variable dépendante est $y=f(x)$. L'ensemble des données est donc un tableau $y$ en fonction de $x$. Les paramètres $a$ et $b$ sont respectivement la pente et l'ordonnée à l'origine.    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb66407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# -------------------------------------------------------------------------------------------\n",
    "# Définition du modèle: \n",
    "def modele_lineaire(x, a, b):\n",
    "    \"\"\"\n",
    "    Modèle : \n",
    "        f(x) = ax + b\n",
    "    variable indépendante: \n",
    "        x\n",
    "    variable dépendante: \n",
    "        y = f(x) \n",
    "    paramètres: \n",
    "        a, b \n",
    "    \"\"\"\n",
    "    return a * x + b\n",
    "\n",
    "# -------------------------------------------------------------------------------------------\n",
    "# Génération d'un ensemble de données factices (les valeurs numérique peuvent être changé pour tester la méthode. Par exemple, la variable scale permet de rendre les données de plus en plus bruitées.)\n",
    "np.random.seed(0)\n",
    "x_data = np.linspace(.1, 9.8, 50)\n",
    "y_data = 2 * x_data + 3 + np.random.normal(scale=1, size=x_data.size)  # Ajout de bruit gaussien\n",
    "incertitude_x = 0.2  # Incertitude sur x_data\n",
    "incertitude_y = 0.5  # Incertitude sur y_data\n",
    "\n",
    "# -------------------------------------------------------------------------------------------\n",
    "# Ajustement du modèle \n",
    "popt, pcov = curve_fit(modele_lineaire, x_data, y_data)\n",
    "\n",
    "# Paramètres optimaux obtenus:\n",
    "a_fit, b_fit = popt\n",
    "\n",
    "# -------------------------------------------------------------------------------------------\n",
    "# Calcul des incertitudes sur les paramètres optimaux\n",
    "a_uncertainty, b_uncertainty = np.sqrt(np.diag(pcov))\n",
    "\n",
    "# -------------------------------------------------------------------------------------------\n",
    "# Calcul du coefficient de détermination\n",
    "y_pred = modele_lineaire(x_data, a_fit, b_fit) # Prédiction du modèle\n",
    "y_mean = np.mean(y_data)\n",
    "r_squared = 1 - np.sum((y_data - y_pred)**2) / np.sum((y_data - y_mean)**2)\n",
    "\n",
    "# -------------------------------------------------------------------------------------------\n",
    "# Affichage des résultats\n",
    "print(f\"Paramètres optimaux: a={a_fit}, b={b_fit}\")\n",
    "print(f\"Incertitude sur les paramètres optimaux: delta_a={a_uncertainty}, delta_b={b_uncertainty}\")\n",
    "print(f\"Coefficient de détermination R²: {r_squared}\")\n",
    "\n",
    "# Visualisation des données et du modèle\n",
    "plt.errorbar(x_data, y_data, xerr=incertitude_x, yerr=incertitude_y, fmt='o', label='Données')\n",
    "plt.plot(x_data, modele_lineaire(x_data, a_fit, b_fit), color='red', label='Modèle optimal')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.xlim(0, 10)  # Remplacez min_x_value et max_x_value par vos valeurs minimale et maximale pour l'axe X\n",
    "plt.ylim(0, 25) \n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef76f66",
   "metadata": {},
   "source": [
    "---\n",
    "## Exemple 2: Modèle polynomial\n",
    "\n",
    "Le modèle linéaire est un polynôme d'ordre 1. La même méthode s'applique pour un polynôme d'ordre quelconque. Nous considérons ici un polynôme d'ordre 2 : $f(x) = ax^2 + bx + c$.    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd663d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def modele_polynome_ordre_2(x, a, b, c):\n",
    "    \"\"\"\n",
    "    Modèle : \n",
    "        f(x) = ax^2 + bx + c\n",
    "    variable indépendante: \n",
    "        x\n",
    "    variable dépendante: \n",
    "        y = f(x) \n",
    "    paramètres: \n",
    "        a, b, c \n",
    "    \"\"\"\n",
    "    return a * x**2 + b * x + c\n",
    "\n",
    "# -------------------------------------------------------------------------------------------\n",
    "# Génération d'un ensemble de données factices \n",
    "np.random.seed(0)\n",
    "x_data = np.linspace(0, 10, 40)\n",
    "y_data = 2.5 * x_data**2 - 15 * x_data + 35 + np.random.normal(scale=2, size=x_data.size)\n",
    "incertitude_x = 0.2  # Incertitude sur x_data\n",
    "incertitude_y = 10  # Incertitude sur y_data\n",
    "\n",
    "# -------------------------------------------------------------------------------------------\n",
    "# Ajustement du modèle \n",
    "popt, pcov = curve_fit(modele_polynome_ordre_2, x_data, y_data)\n",
    "\n",
    "# Paramètres optimaux obtenus:\n",
    "a_fit, b_fit, c_fit = popt\n",
    "\n",
    "# -------------------------------------------------------------------------------------------\n",
    "# Calcul des incertitudes sur les paramètres optimaux\n",
    "a_uncertainty, b_uncertainty, c_uncertainty = np.sqrt(np.diag(pcov))\n",
    "\n",
    "# -------------------------------------------------------------------------------------------\n",
    "# Calcul du coefficient de détermination\n",
    "y_pred = modele_polynome_ordre_2(x_data, a_fit, b_fit, c_fit) # Prédiction du modèle\n",
    "y_mean = np.mean(y_data)\n",
    "r_squared = 1 - np.sum((y_data - y_pred)**2) / np.sum((y_data - y_mean)**2)\n",
    "\n",
    "# -------------------------------------------------------------------------------------------\n",
    "# Affichage des résultats\n",
    "print(f\"Paramètres optimaux: a={a_fit}, b={b_fit}, b={c_fit}\")\n",
    "print(f\"Incertitude sur les paramètres optimaux: delta_a={a_uncertainty}, delta_b={b_uncertainty}, delta_c={b_uncertainty}\")\n",
    "print(f\"Coefficient de détermination R²: {r_squared}\")\n",
    "\n",
    "# Visualisation des données et du modèle\n",
    "plt.errorbar(x_data, y_data, xerr=incertitude_x, yerr=incertitude_y, fmt='o', label='Données')\n",
    "plt.plot(x_data, modele_polynome_ordre_2(x_data, a_fit, b_fit, c_fit), color='red', label='Modèle optimal')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.xlim(0, 10)  # Remplacez min_x_value et max_x_value par vos valeurs minimale et maximale pour l'axe X\n",
    "plt.ylim(0, 150) \n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c925223b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149f97a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# -------------------------------------------------------------------------------------------\n",
    "def modele_oscillation_amortie(t, A_0, omega, gamma, phi):\n",
    "    \"\"\"\n",
    "    Modèle d'oscillation amortie :  x(t) = A_0 * exp(-gamma/2 * t) * cos(omega * t + phi) \n",
    "        Variable indépendante:\n",
    "            t : temps\n",
    "        Variable dépendante:\n",
    "            x : position\n",
    "        Paramètres:\n",
    "            A_0 : amplitude initiale\n",
    "            omega : fréquence angulaire\n",
    "            gamma : taux d'amortissement\n",
    "            phi : phase initiale\n",
    "    \"\"\"\n",
    "    return A_0 * np.exp(-gamma/2 * t) * np.cos(omega * t + phi)\n",
    "\n",
    "# -------------------------------------------------------------------------------------------\n",
    "# Générer des données factices pour l'oscillation amortie\n",
    "# -------------------------------------------------------------------------------------------\n",
    "A_0_true = 5.0\n",
    "omega_true = 2.0\n",
    "gamma_true = 0.2\n",
    "phi_true = np.pi / 4\n",
    "np.random.seed(0)\n",
    "t_data = np.linspace(0, 10, 100)\n",
    "y_data = modele_oscillation_amortie(t_data, A_0_true, omega_true, gamma_true, phi_true) + np.random.normal(scale=0.1, size=t_data.size)\n",
    "\n",
    "# Générer des incertitudes pour les données temporelles\n",
    "uncertainty_t = np.abs(np.random.normal(scale=.2, size=t_data.size))  # Incertitude de 0.05 unités de temps\n",
    "\n",
    "# Générer des incertitudes pour les données d'amplitude\n",
    "uncertainty_y = np.abs(np.random.normal(scale=.2, size=y_data.size))  # Incertitude de 0.1 sur les données d'amplitude\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------------------------------\n",
    "# Réaliser l'ajustement de courbe en tenant compte des incertitudes sur les données d'amplitude et de temps\n",
    "popt, pcov = curve_fit(modele_oscillation_amortie, t_data, y_data, sigma=uncertainty_y, absolute_sigma=True, p0=[A_true, omega_true, gamma_true, phi_true])\n",
    "\n",
    "# Paramètres ajustés\n",
    "A_fit, omega_fit, gamma_fit, phi_fit = popt\n",
    "\n",
    "# Incertitudes sur les paramètres\n",
    "A_uncertainty, omega_uncertainty, gamma_uncertainty, phi_uncertainty = np.sqrt(np.diag(pcov))\n",
    "\n",
    "# -------------------------------------------------------------------------------------------\n",
    "# Affichage des résultats\n",
    "print(f\"Paramètres ajustés: A={A_fit}, omega={omega_fit}, gamma={gamma_fit}, phi={phi_fit}\")\n",
    "print(f\"Incertitudes sur les paramètres: A={A_uncertainty}, omega={omega_uncertainty}, gamma={gamma_uncertainty}, phi={phi_uncertainty}\")\n",
    "\n",
    "# -------------------------------------------------------------------------------------------\n",
    "# Visualisation des données et de l'ajustement\n",
    "plt.errorbar(t_data, y_data, yerr=uncertainty_y, xerr=uncertainty_t, fmt='o', label='Données')\n",
    "plt.plot(t_data, modele_oscillation_amortie(t_data, *popt), 'r-', label='Modèle ajusté')\n",
    "plt.xlabel('Temps')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd2a91f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def Afct(omega, Ae, Q, omega0):\n",
    "    \"\"\"\n",
    "    Modèle d'amplitude en fonction de la fréquence :\n",
    "    Ae : amplitude de l'oscillateur non forcé\n",
    "    Q : facteur de qualité\n",
    "    omega0 : fréquence propre\n",
    "    omega : fréquence du forçage\n",
    "    \"\"\"\n",
    "    return Ae * (omega0 / omega) / (np.sqrt((omega0 / omega - omega / omega0)**2 + 1 / Q**2))\n",
    "\n",
    "# Générer des données factices pour l'amplitude en fonction de la fréquence\n",
    "np.random.seed(0)\n",
    "omega_data = np.linspace(1, 6, 50)\n",
    "Ae_true = 1.0\n",
    "omega0_true = 2.0\n",
    "Q_true = 10\n",
    "amplitude_data = Afct(omega_data, Ae_true, Q_true, omega0_true) + np.random.normal(scale=0.1, size=omega_data.size)\n",
    "\n",
    "# Ajouter des incertitudes sur les données d'amplitude\n",
    "uncertainty_amplitude = np.abs(np.random.normal(scale=.5, size=omega_data.size))\n",
    "\n",
    "# Réaliser l'ajustement de courbe\n",
    "popt, pcov = curve_fit(Afct, omega_data, amplitude_data, sigma=uncertainty_amplitude, absolute_sigma=True, p0=[Ae_true, Q_true, omega0_true])\n",
    "\n",
    "# Paramètres ajustés\n",
    "Ae_fit, omega0_fit, Q_fit = popt\n",
    "\n",
    "# Incertitudes sur les paramètres\n",
    "Ae_uncertainty, omega0_uncertainty, Q_uncertainty = np.sqrt(np.diag(pcov))\n",
    "\n",
    "# Affichage des résultats\n",
    "print(f\"Paramètres ajustés: Ae={Ae_fit}, omega0={omega0_fit}, Q={Q_fit}\")\n",
    "print(f\"Incertitudes sur les paramètres: Ae={Ae_uncertainty}, omega0={omega0_uncertainty}, Q={Q_uncertainty}\")\n",
    "\n",
    "\n",
    "omega_data_fit = np.linspace(1, 6, 200)\n",
    "\n",
    "# Visualisation des données et de l'ajustement\n",
    "plt.errorbar(omega_data, amplitude_data, yerr=uncertainty_amplitude, fmt='o', label='Données')\n",
    "plt.plot(omega_data_fit, Afct(omega_data_fit, *popt), 'r-', label='Modèle ajusté')\n",
    "plt.xlabel('Fréquence')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380e2cfd",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Définition du modèle de titrage (par exemple, une courbe sigmoïde)\n",
    "def modele_titrage(volume, Veq, pKa, pH_init, pH_fin):\n",
    "    \"\"\"\n",
    "    Modèle de titrage :\n",
    "    volume : volume de solution titrante ajoutée\n",
    "    Veq : volume équivalent\n",
    "    pKa : pKa de l'acide/base titrée\n",
    "    pH_init : pH initial\n",
    "    pH_fin : pH final\n",
    "    \"\"\"\n",
    "    return pH_init + (pH_fin - pH_init) / (1 + 10**(pKa - volume + Veq))\n",
    "\n",
    "# Générer des données factices pour un titrage\n",
    "np.random.seed(0)\n",
    "volume_data = np.linspace(20, 40, 100)\n",
    "Veq_true = 25.0\n",
    "pKa_true = 4.0\n",
    "pH_init_true = 2.0\n",
    "pH_fin_true = 12.0\n",
    "pH_data = modele_titrage(volume_data, Veq_true, pKa_true, pH_init_true, pH_fin_true) + np.random.normal(scale=0.1, size=volume_data.size)\n",
    "\n",
    "# Ajouter des incertitudes sur les données de pH\n",
    "uncertainty_pH = np.abs(np.random.normal(scale=0.05, size=volume_data.size))\n",
    "\n",
    "# Réaliser l'ajustement de courbe\n",
    "popt, pcov = curve_fit(modele_titrage, volume_data, pH_data, sigma=uncertainty_pH, p0=[Veq_true, pKa_true, pH_init_true, pH_fin_true])\n",
    "\n",
    "# Paramètres ajustés\n",
    "Veq_fit, pKa_fit, pH_init_fit, pH_fin_fit = popt\n",
    "\n",
    "# Incertitudes sur les paramètres\n",
    "Veq_uncertainty, pKa_uncertainty, pH_init_uncertainty, pH_fin_uncertainty = np.sqrt(np.diag(pcov))\n",
    "\n",
    "# Affichage des résultats\n",
    "print(f\"Paramètres ajustés: Veq={Veq_fit}, pKa={pKa_fit}, pH_init={pH_init_fit}, pH_fin={pH_fin_fit}\")\n",
    "print(f\"Incertitudes sur les paramètres: Veq={Veq_uncertainty}, pKa={pKa_uncertainty}, pH_init={pH_init_uncertainty}, pH_fin={pH_fin_uncertainty}\")\n",
    "\n",
    "# Visualisation des données et de l'ajustement\n",
    "plt.errorbar(volume_data, pH_data, yerr=uncertainty_pH, fmt='o', label='Données')\n",
    "plt.plot(volume_data, modele_titrage(volume_data, *popt), 'r-', label='Modèle ajusté')\n",
    "plt.xlabel('Volume de solution titrante ajoutée')\n",
    "plt.ylabel('pH')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c6380f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Définition du modèle pour le courant dans la bobine d'induction\n",
    "def modele_courant(t, I0, tau):\n",
    "    \"\"\"\n",
    "    Modèle de courant dans la bobine d'induction :\n",
    "    t : temps\n",
    "    I0 : courant initial\n",
    "    tau : constante de temps\n",
    "    \"\"\"\n",
    "    return I0 * np.exp(-t / tau)\n",
    "\n",
    "# Générer des données factices pour le courant dans la bobine d'induction\n",
    "np.random.seed(0)\n",
    "t_data = np.linspace(0, 10, 100)\n",
    "I0_true = 5.0\n",
    "tau_true = 2.0\n",
    "courant_data = modele_courant(t_data, I0_true, tau_true) + np.random.normal(scale=0.1, size=t_data.size)\n",
    "\n",
    "# Ajouter des incertitudes sur les données de courant\n",
    "uncertainty_courant = np.abs(np.random.normal(scale=0.05, size=t_data.size))\n",
    "\n",
    "# Réaliser l'ajustement de courbe\n",
    "popt, pcov = curve_fit(modele_courant, t_data, courant_data, sigma=uncertainty_courant, p0=[I0_true, tau_true])\n",
    "\n",
    "# Paramètres ajustés\n",
    "I0_fit, tau_fit = popt\n",
    "\n",
    "# Incertitudes sur les paramètres\n",
    "I0_uncertainty, tau_uncertainty = np.sqrt(np.diag(pcov))\n",
    "\n",
    "# Affichage des résultats\n",
    "print(f\"Paramètres ajustés: I0={I0_fit}, tau={tau_fit}\")\n",
    "print(f\"Incertitudes sur les paramètres: I0={I0_uncertainty}, tau={tau_uncertainty}\")\n",
    "\n",
    "# Visualisation des données et de l'ajustement\n",
    "plt.errorbar(t_data, courant_data, yerr=uncertainty_courant, fmt='o', label='Données')\n",
    "plt.plot(t_data, modele_courant(t_data, *popt), 'r-', label='Modèle ajusté')\n",
    "plt.xlabel('Temps')\n",
    "plt.ylabel('Courant')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9259bd14",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Définition du modèle pour l'allumage de la bobine\n",
    "def modele_allumage(t, I0, tau):\n",
    "    \"\"\"\n",
    "    Modèle d'allumage de la bobine :\n",
    "    t : temps\n",
    "    I0 : intensité lumineuse initiale\n",
    "    tau : constante de temps\n",
    "    \"\"\"\n",
    "    return I0 * (1 - np.exp(-t / tau))\n",
    "\n",
    "# Générer des données factices pour l'allumage de la bobine\n",
    "np.random.seed(0)\n",
    "t_data = np.linspace(0, 10, 100)\n",
    "I0_true = 5.0\n",
    "tau_true = 2.0\n",
    "intensite_data = modele_allumage(t_data, I0_true, tau_true) + np.random.normal(scale=0.1, size=t_data.size)\n",
    "\n",
    "# Ajouter des incertitudes sur les données d'intensité lumineuse\n",
    "uncertainty_intensite = np.abs(np.random.normal(scale=0.05, size=t_data.size))\n",
    "\n",
    "# Réaliser l'ajustement de courbe\n",
    "popt, pcov = curve_fit(modele_allumage, t_data, intensite_data, sigma=uncertainty_intensite, p0=[I0_true, tau_true])\n",
    "\n",
    "# Paramètres ajustés\n",
    "I0_fit, tau_fit = popt\n",
    "\n",
    "# Incertitudes sur les paramètres\n",
    "I0_uncertainty, tau_uncertainty = np.sqrt(np.diag(pcov))\n",
    "\n",
    "# Affichage des résultats\n",
    "print(f\"Paramètres ajustés: I0={I0_fit}, tau={tau_fit}\")\n",
    "print(f\"Incertitudes sur les paramètres: I0={I0_uncertainty}, tau={tau_uncertainty}\")\n",
    "\n",
    "# Visualisation des données et de l'ajustement\n",
    "plt.errorbar(t_data, intensite_data, yerr=uncertainty_intensite, fmt='o', label='Données')\n",
    "plt.plot(t_data, modele_allumage(t_data, *popt), 'r-', label='Modèle ajusté')\n",
    "plt.xlabel('Temps')\n",
    "plt.ylabel('Intensité lumineuse')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e111de",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Définition du modèle d'apprentissage machine\n",
    "def modele_M(xy, a, b, c, d, e, f):\n",
    "    \"\"\"\n",
    "    Modèle d'apprentissage machine dépendant de deux variables (x, y):\n",
    "    xy : tuple contenant les variables x et y\n",
    "    a, b, c, d, e, f : paramètres du modèle\n",
    "    \"\"\"\n",
    "    x, y = xy\n",
    "    return a * x**2 + b * y**2 + c * x * y + d * x + e * y + f\n",
    "\n",
    "# Générer des données factices pour x et y\n",
    "np.random.seed(0)\n",
    "x_data = np.random.uniform(0, 10, 100)\n",
    "y_data = np.random.uniform(0, 10, 100)\n",
    "\n",
    "# Générer des données factices pour le modèle\n",
    "a_true = 2.0\n",
    "b_true = -1.0\n",
    "c_true = 0.5\n",
    "d_true = 1.0\n",
    "e_true = -2.0\n",
    "f_true = 3.0\n",
    "modele_data = modele_M((x_data, y_data), a_true, b_true, c_true, d_true, e_true, f_true) + np.random.normal(scale=1.0, size=x_data.size)\n",
    "\n",
    "# Réaliser l'ajustement de courbe\n",
    "popt, pcov = curve_fit(modele_M, (x_data, y_data), modele_data)\n",
    "\n",
    "# Paramètres ajustés\n",
    "a_fit, b_fit, c_fit, d_fit, e_fit, f_fit = popt\n",
    "\n",
    "# Affichage des résultats\n",
    "print(f\"Paramètres ajustés: a={a_fit}, b={b_fit}, c={c_fit}, d={d_fit}, e={e_fit}, f={f_fit}\")\n",
    "\n",
    "# Visualisation des données et de l'ajustement\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x_data, y_data, modele_data, label='Données')\n",
    "x_fit, y_fit = np.meshgrid(np.linspace(0, 10, 50), np.linspace(0, 10, 50))\n",
    "modele_fit = modele_M((x_fit, y_fit), a_fit, b_fit, c_fit, d_fit, e_fit, f_fit)\n",
    "ax.plot_surface(x_fit, y_fit, modele_fit, color='r', alpha=0.5, label='Modèle ajusté')\n",
    "ax.set_xlabel('X Data')\n",
    "ax.set_ylabel('Y Data')\n",
    "ax.set_zlabel('Modèle Data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc755ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ipyvolume as ipv\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Définition du modèle d'apprentissage machine\n",
    "def modele_M(xy, a, b, c, d, e, f):\n",
    "    \"\"\"\n",
    "    Modèle d'apprentissage machine dépendant de deux variables (x, y):\n",
    "    xy : tuple contenant les variables x et y\n",
    "    a, b, c, d, e, f : paramètres du modèle\n",
    "    \"\"\"\n",
    "    x, y = xy\n",
    "    return a * x**2 + b * y**2 + c * x * y + d * x + e * y + f\n",
    "\n",
    "# Générer des données factices pour x et y\n",
    "np.random.seed(0)\n",
    "x_data = np.random.uniform(0, 10, 100)\n",
    "y_data = np.random.uniform(0, 10, 100)\n",
    "\n",
    "# Générer des données factices pour le modèle\n",
    "a_true = 2.0\n",
    "b_true = -1.0\n",
    "c_true = 0.5\n",
    "d_true = 1.0\n",
    "e_true = -2.0\n",
    "f_true = 3.0\n",
    "modele_data = modele_M((x_data, y_data), a_true, b_true, c_true, d_true, e_true, f_true) + np.random.normal(scale=1.0, size=x_data.size)\n",
    "\n",
    "# Réaliser l'ajustement de courbe\n",
    "popt, pcov = curve_fit(modele_M, (x_data, y_data), modele_data)\n",
    "\n",
    "# Paramètres ajustés\n",
    "a_fit, b_fit, c_fit, d_fit, e_fit, f_fit = popt\n",
    "\n",
    "# Affichage des résultats\n",
    "print(f\"Paramètres ajustés: a={a_fit}, b={b_fit}, c={c_fit}, d={d_fit}, e={e_fit}, f={f_fit}\")\n",
    "\n",
    "# Visualisation des données et de l'ajustement avec ipyvolume\n",
    "x_fit, y_fit = np.meshgrid(np.linspace(0, 10, 50), np.linspace(0, 10, 50))\n",
    "modele_fit = modele_M((x_fit, y_fit), a_fit, b_fit, c_fit, d_fit, e_fit, f_fit)\n",
    "ipv.figure()\n",
    "ipv.plot_surface(x_fit, y_fit, modele_fit, color='red')\n",
    "ipv.scatter(x_data, y_data, modele_data, color='blue', size=2)\n",
    "ipv.xlabel('X Data')\n",
    "ipv.ylabel('Y Data')\n",
    "ipv.zlabel('Modèle Data')\n",
    "ipv.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8169e24c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# Données des paramètres ajustés et des incertitudes\n",
    "parametres = [\n",
    "    [\"Ae\", 4.7277682605640905, 0.011991769622067454],\n",
    "    [\"omega\", 2.0027307499175366, 0.00094044868866963],\n",
    "    [\"gamma\", 0.19826682889546587, 0.0014223412651209158],\n",
    "    [\"phi\", 0.7845555630172037, 0.001472170894839975]\n",
    "]\n",
    "\n",
    "# Affichage du tableau\n",
    "print(tabulate(parametres, headers=[\"Paramètres\", \"Ajusté\", \"Incertitude\"], tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ee861b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
